{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647db759-3323-40b1-aa8c-2feb3ab23f62",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:50px; font-family:Helvetica ; font-weight : normal; color : #fe346e; text-align: center;\"> Exploratory Data Analysis</h1>\n",
    "<h2 style = \"font-size:40px; font-family:Helvetica ; font-weight : normal; text-align: center;\"> Classification </h2>\n",
    "<br><br>\n",
    "\n",
    "<img src='https://res.cloudinary.com/djz27k5hg/image/upload/v1715612126/EDA/dw1xwbh1g2c85izletjs.png' width=\"200\"  style=\"float:center\" align=\"center\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='padding:15px'>\n",
    "<a href=\"https://colab.research.google.com/github/rribeiro-sci/EDA_laboratory/blob/main/5-Classification.ipynb\" target=\"_blank\">\n",
    "<img alt=\"Colab\" src=\"https://res.cloudinary.com/djz27k5hg/image/upload/v1637335713/badges/colab-badge_hh0uyl.svg\" height=\"25\" style=\"margin:20px\">\n",
    "</a>\n",
    "\n",
    "</div> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e54d1-377b-4530-99e0-94f47be2b81e",
   "metadata": {},
   "source": [
    "# Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9dfae-c93c-4866-bc66-34af5d17c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "data = {\n",
    "    'concentration': [0, 5, 10, 12, 17, 20, 25],\n",
    "    'absorbance': [0, 0.1824, 0.3146, 0.3698, 0.4879,0.5498,0.6100]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e445d5-c097-49ae-b2e5-f8112ccc3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract concentration and absorbance values\n",
    "concentration = df['concentration'].values.reshape(-1, 1)  # Reshape for sklearn (THIS IS IMPORTANT)\n",
    "absorbance = df['absorbance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d892462-e0c2-4c30-8f92-29e08fdb382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize and fit the linear regression model\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(concentration, absorbance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccc460-6e45-43a1-8e26-8c6473f42ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396132f8-0330-4574-af0f-a889e8ef993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the slope and intercept from the model\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print the linear regression results\n",
    "print(f\"Slope: {slope}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "print(f\"R-squared: {model.score(concentration, absorbance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3ff6c-0d3a-4c49-95ba-05a6a7d4dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate values for the fitted line\n",
    "fitted_absorbance = model.predict(concentration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0d11a-51a3-4bbf-b4da-8e16c118bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data points\n",
    "plt.scatter(concentration, absorbance, label='Data Points')\n",
    "\n",
    "# Plot the fitted line\n",
    "plt.plot(concentration, fitted_absorbance, color='red', label='Fitted Line')\n",
    "\n",
    "# Plot a line passing through the origin with the same slope as the fitted line\n",
    "origin_line_x = np.array([-1, np.min(concentration)])  # Use np.max() to get the maximum concentration value\n",
    "origin_line_y = slope * origin_line_x\n",
    "plt.plot(origin_line_x, origin_line_y, linestyle='--', color='blue', label='Line through Origin')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('BSA Âµg/mL')\n",
    "plt.ylabel('Absorbance 595 nm')\n",
    "plt.grid()\n",
    "\n",
    "# Annotate the equation of the line and the R-squared value\n",
    "equation_text = f'Abs = {slope:.2f}[conc]'\n",
    "rsquared_text = f'R-squared: {model.score(concentration, absorbance):.2f}'\n",
    "plt.text(0.1, 0.5, equation_text, fontsize=12, color='black')\n",
    "plt.text(0.1, 0.45, rsquared_text, fontsize=12, color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f8c3d-2d97-422e-8ed3-3b345147ffb0",
   "metadata": {},
   "source": [
    "# Logistic Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324b718-6ddd-4b01-a563-84442c8a1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f154d-da85-4883-b611-3c1a395655b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([ 2.04335340e+04, 8.53159941e+04,\n",
    "                    3.56219283e+05, 1.48731992e+06,\n",
    "                    6.20999665e+06, 1.26892178e+07,\n",
    "                    1.08259323e+08, 2.21212056e+08, \n",
    "                    1.88729264e+09, 3.85640584e+09])\n",
    "\n",
    "y_data = np.array([ 1.91360620e+04, 1.90926959e+04,\n",
    "                    1.89137725e+04, 1.81963673e+04,\n",
    "                    1.53607779e+04, 5.53058869e+03,\n",
    "                    2.12431583e+02, 3.95457265e+01,\n",
    "                    2.02482030e+01, 1.64053172e+01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84851e19-4dc3-460c-afdc-73c41bbbbdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the y_data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "y_data_normalized = scaler.fit_transform(y_data.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "def eqfit(x, bottom, top, kd):\n",
    "    \n",
    "    return bottom + (top-bottom)/(1+(x/kd))\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(eqfit, x_data, y_data_normalized, maxfev=5000)\n",
    "\n",
    "xfit = np.geomspace(1E4,1E10, 50000)\n",
    "yfit = eqfit(xfit, *popt)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_data,y_data_normalized)\n",
    "plt.plot(xfit, yfit, 'r')\n",
    "plt.title('Dose-response Curve')\n",
    "plt.xlabel('[ligand]')\n",
    "plt.ylabel('efficency')\n",
    "\n",
    "# Annotate the fitted parameters\n",
    "IC50 = popt[-1]\n",
    "text = f'IC50 = {IC50:.2e}'\n",
    "plt.text(1E8, 0.5, text, fontsize=12, color='black')\n",
    "\n",
    "\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee0e48-0c63-48d0-af18-359bce0f6b6e",
   "metadata": {},
   "source": [
    "# Classification models that will predict which class the flower is based on petal and sepal sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b309c30-c63c-4dd3-82e5-5d3a7962962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# importing iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673ef062-a278-406e-9ee0-a3edb09f892f",
   "metadata": {},
   "source": [
    "### Standardize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e805a-6eac-4908-aa74-64e0ba69c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_data =scaler.fit_transform(iris.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9f1a8-090d-44ae-a143-6007e4820e50",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test data\n",
    "\n",
    "Creating a train and test class. As the names suggest, we will train our model on the train set, and test the model on the test set. We will randomly select **80% of the data to be in our training, and 20% as test.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f158df7-6fc0-412e-8de2-a77cceff0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing splitter from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, iris.target, test_size=0.2, random_state=1, stratify = iris.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988719e-e645-4a5b-873e-5743212c1463",
   "metadata": {},
   "source": [
    "by \"stratifying\" on `iris.target` we assure that the different classes are represented proportionally to the amount in the total data (this makes sure that all of class 1 is not in the test group only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41020574-f43e-44b5-9534-a28354c86a86",
   "metadata": {},
   "source": [
    "## k-Nearest-Neighbors Model\n",
    "\n",
    "k-NN is a **supervised machine learning model**.The model then trains on that data to learn how to map the inputs to the desired output so it can learn to make predictions on unseen data. \n",
    " \n",
    "\n",
    "\n",
    "### Building and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbfbe63-3c43-4e0f-9aab-fb52247538c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model  = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3580c70",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "Once the model is trained, we can use the `predict()` method on our model to make predictions on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b94b4-8987-4f80-af90-b0a755a94902",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f1185",
   "metadata": {},
   "source": [
    "### Is our model accurate?\n",
    "\n",
    "we can use the `score()` method and pass in our test input and target data to see how well our model predictions match up to the actual results. \n",
    "\n",
    "Accuracy is the ratio of correctly predicted instances to the total number of instances in the dataset. It's a straightforward metric that tells you how often the classifier is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0507f-33eb-48bc-91a6-be36ff29742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829ff6e",
   "metadata": {},
   "source": [
    "### Evaluating model's performance\n",
    "\n",
    "In machine learning, there are different evaluation metrics: \n",
    "* Confusion Matrix\n",
    "* F1 score, \n",
    "* Precision\n",
    "* Recall\n",
    "\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_heatmap = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                    display_labels=iris.target_names, )\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "cm_heatmap.plot(ax=ax, cmap=plt.cm.Blues,)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ae746",
   "metadata": {},
   "source": [
    "#### How to interpret the confusion matrix?\n",
    "\n",
    "The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.\n",
    "\n",
    "### F1 score\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall. F1 score = 2 / (1 / Precision + 1 / Recall)\n",
    "\n",
    "* **Precision:** Precision is the ratio of true positive predictions to the total number of positive predictions made by the model. It measures the accuracy of positive predictions.\n",
    "\n",
    "* **Recall:** Recall, also known as sensitivity or true positive rate, is the ratio of true positive predictions to the total number of actual positive instances in the data. It measures the model's ability to capture all positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42873f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, average='macro') #when you want to know the overall performance of the model across all classes, treating each class equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c2033",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a40c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f0b44",
   "metadata": {},
   "source": [
    "## k-Fold Cross-Validation\n",
    "\n",
    "Cross-validation is when the dataset is randomly split up into âkâ groups. One of the groups is used as the test set and the rest are used as the training set. The model is trained on the training set and scored on the test set. Then the process is repeated until each unique group as been used as the test set.\n",
    "\n",
    "<img src='https://res.cloudinary.com/djz27k5hg/image/upload/v1715848525/EDA/tgu7pavh49kiixdnuloa.webp' width=\"600\" style=\"float:center\" />\n",
    "<br>\n",
    "\n",
    "Cross-validation gives the model an opportunity to test on multiple splits so we can get a better idea on how the model will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf90ad-0a50-4e8c-bed2-7e1d83225b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris.target\n",
    "scores=[]\n",
    "f1=[]\n",
    "for train_index, test_index in kf.split(X_data):\n",
    "    kf_X_train, kf_X_test = X_data[train_index], X_data[test_index]\n",
    "    kf_y_train, kf_y_test = y[train_index], y[test_index]\n",
    "\n",
    "    knn_model  = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_model.fit(kf_X_train, kf_y_train)\n",
    "    kf_y_pred = knn_model.predict(kf_X_test)\n",
    "\n",
    "    score = round(knn_model.score(kf_X_test, kf_y_test),3)\n",
    "    f1_score_macro = round(f1_score(kf_y_test, kf_y_pred, average='macro'),3)\n",
    "    scores.append(score)\n",
    "    f1.append(f1_score_macro)\n",
    "    print(score, f1_score_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f884c-3be1-4246-b0b8-e43214b23335",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(scores))\n",
    "print(np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dad409-c157-4dce-977e-75e10b7cec86",
   "metadata": {},
   "source": [
    "This is a more accurate representation of how our model will perform on unseen data than our earlier testing using the holdout method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f0ed3-0d60-4afe-9633-3ded2d76cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compbio",
   "language": "python",
   "name": "compbio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
